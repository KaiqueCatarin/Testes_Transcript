 Bom, salve, salve! Então bora pra mais um vídeo aqui falando sobre MLflow. E hoje a gente vai descobrir como que a gente faz o deploy automático de um modelo, por exemplo, sem precisar alterar o script Python que está consumindo o modelo. Então, na versão anterior, do vídeo anterior, a gente viu que bastava alterar a versão do modelo no script Python e pronto. A gente seria capaz de fazer escoragem novas, né, a partir de um modelo novo que foi deployado. Mas, e se a gente não quiser ter que ficar alterando o script Python com uma versão nova que surgiu? E se a gente quisesse que esse script sempre buscasse a última versão do modelo funcional lá, deployado no MLflow, registrado, melhor dizendo, no MLflow? Então é isso que a gente vai fazer agora. Então bora aqui pro MLflow ver como é que isso acontece. Então a gente tem aqui novamente o nosso MLflow, bonitinho. A gente tem um modelo que está registrado, né, que é esse modelo aqui, ó, versão 2. Daqui é a versão do modelo, versão 2, tá lá bonitão. E a gente tem o nosso script Python que também estava aqui, ó, funcionando. Tá funcionando. Se a gente der, até executei aqui antes, né, vou fechar aqui pra vocês verem, ó. Então a gente tá com o script Python, basta executar, pay, pay, pay, ó, funcionou. Ele foi lá, buscou a terceira, desculpa, a segunda versão do modelo. E aí ele tá fazendo a escoragem nos dados que a gente importou aqui da nossa ABT. Legal. Tá, mas como que a gente pode pegar sempre a última versão, não ter que abrir esse código, caso altere lá a versão do modelo, e tenha que passar o número 2 aqui, né? Então vou dar mais um zoom, talvez esteja pequeno aí, não sei. É o seguinte, a gente vai usar o client do MLflow, beleza? A gente não usou ele ainda. O client do MLflow é pra gente acessar a API do MLflow pra consumir algumas informações que o servidor pode nos entregar. Então pra gente fazer isso, eu vou chamar de client mlflow.client.mlflowclient. Tá aqui, eu tenho o mlflowclient na minha mão, tá? Eu vou executar esse cara aqui só pra gente ver o que é que ele tem. Então primeiro eu tô executando essa primeira parte pra gente ver, e depois aqui o client sozinho. Quando a gente executa o client sozinho, ele vai mostrar que, olha, tem um objeto aqui do tipo MLflowclient. Legal. Agora eu quero, por exemplo, buscar as últimas versões de um modelo. Eu posso fazer get lastVersions, desse jeito. E passo o nome do modelo. Quando eu passar o nome do modelo, o nome do modelo é o nosso churny.tellmywhy. Se a gente faz isso, olha só o que ele retorna ali pra gente. Ele retorna uma lista de modelos que vai ter, por exemplo, aqui a descrição. Não tem nada na descrição. Quando que esse cara foi criado. Tem aqui o creation timestamp. O nome do modelo. A run ID. E tem também aqui a versão. A última coisa aqui é a versão do modelo. Então desse jeito ele tá trazendo pra gente as últimas versões do nosso modelo. Então guest lastVersions. O que a gente pode fazer com isso? A gente pode colocar isso numa lista e pegar a maior versão de forma automática. Então eu posso colocar aqui Versions, por exemplo. Vai ser um i for i in isso aqui. Ponto version. Se a gente executar, olha só. Ele tá trazendo o dois com aspas. Ou seja, é uma string. A gente pode converter essa string aqui mesmo pra int. E calcular o max disso tudo. Então é uma list comprehension aí, né? Tem que lembrar um pouquinho das aulas de Python. E aí eu tenho a version aqui. Quando a gente dá um ctrl enter, olha só. Apareceu ali, ó. Version. O número 2. E pronto. Então eu tô pegando aí a última versão. O que eu preciso fazer agora? Passar essa última versão aqui de quando eu invoco o meu modelo. Então eu vou colocar um F e version. Prontinho. Então eu vou até excluir tudo. Vou até excluir tudo isso daqui. Pra gente fazer e ver que as predições se mantêm as mesmas. Então olha só. A version tá aqui. Deu certo. Então eu alterei aqui a versão pra ele pegar de forma automática. A versão mais alta. A versão mais recente. E funcionou. Será que tá funcionando mesmo? O que nós vamos fazer agora? Vamos treinar um novo algoritmo. Aqui tem o nosso modelo de Random Forest, né? Que a gente falou bastante. Então vamos treinar um novo algoritmo, né? Vou treinar aqui um modelo de Random Forest mesmo. Só que eu vou trocar alguns parâmetros aqui. Vou trocar, por exemplo, esse minsamplesleaf. Vou colocar 75 no lugar de... Ou 35 no lugar de 50. E vamos executar. Pá, pá, pá, pá, pá, pá. Vamos ver o que acontece. Já foi o meu autolog. Tá executando. Executou. Vamos ver como é que foi esse experimento. Então a gente volta lá no Experiment. Vamos dar uma olhada. Olha só. Não conseguimos melhorar. 14 segundos atrás. Mas tá melhor do que o anterior, né? Então eu vou colocar esse cara agora. Vou registrar esse novo modelo lá no nosso Model Churn. Registrei esse novo modelo. Se a gente der uma olhada lá, agora tá na versão 3. Meu Churn aqui tem a versão 3. E agora eu posso pegar esse version 3 aqui e usar na predição. Então eu vou voltar lá pra predição agora. Tô voltando pra predição. Não vou alterar absolutamente nada no meu código. Porque essa etapa aqui já vai pegar a última versão do modelo. Vamos comparar esse score aqui com o que está por vir. 1, 2, 3 e... Olha só. Então a gente tava falando de 0.72. Aqui no algoritmo novo. 0.72, 0.58. E o algoritmo antigo era 0.71, 0.61. Olha só. Então, de fato, o algoritmo mudou sem que a gente precisasse mudar nada no código que vai servir esse modelo. Então isso é muito God. A gente não precisa se preocupar em ficar alterando a versão do modelo agora. Quando o modelo muda no MLflow, automaticamente as aplicações ou a aplicação que está consumindo esse modelo do MLflow já vai receber o modelo novo. E aí você pode colocar, por exemplo, um cache pra esse modelo. Ou seja, de tanto e tanto tempo esse modelo vai ser cacheado e vai durar um tempo esse cache. E depois ele joga fora e importa um modelo novo. Então você tem meio que um auto-deploy, digamos assim. Alterou o modelo no MLflow, a sua aplicação daqui a um tempo vai pegar esse modelo novo sozinha. Então é uma maneira bem interessante pra você pensar nas suas aplicações de modelagem. Sem precisar se preocupar na aplicação, na ponta, que modelo que ela está recebendo. O MLflow toma conta disso pra você, né? A gestão fica no MLflow, não fica no código. Demorou? É isso. Valeu demais. A gente se vê no próximo vídeo. Vamos tentar criar um appzinho diferente mesmo, como é a API, pra servir esse modelo. Demorou? Valeu demais.